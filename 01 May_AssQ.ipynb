{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ef42e7-9c5b-4de6-831d-7dbe88dc8ef3",
   "metadata": {},
   "source": [
    "Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?\n",
    "\n",
    "ANS:-In statistics, a contingency table is a type of table in a matrix format that displays the frequency distribution of the variables. They are heavily used in survey research, business intelligence, engineering, and scientific research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7cb32f-0dfe-420a-97f4-113e90319c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13ead90b-c4e7-445a-b78a-4989881cd410",
   "metadata": {},
   "source": [
    "Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in \n",
    "certain situations?\n",
    "\n",
    "ANS:-The pair confusion matrix computes a 2 by 2 similarity matrix between two clusterings by considering all pairs of samples and counting pairs that are assigned into the same or into different clusters under the true and predicted clusterings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd3c56-6ab0-4c2e-a9a3-610e49634570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "574e8603-c6bf-4235-a1e3-9c19b84f4ee0",
   "metadata": {},
   "source": [
    "Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically \n",
    "used to evaluate the performance of language models?\n",
    "\n",
    "ANS:-Extrinsic metrics measure the fairness of system outputs, which are directly related to the downstream bias that affects end users. However, they only inform the fairness of the combined system components, whereas in- trinsic metrics directly analyze the bias encoded in the contextualized language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7fc68b-7636-4c82-b6a4-1409fd9d4ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f3ac4e8-3226-423e-b936-ab65e1b2c58e",
   "metadata": {},
   "source": [
    "Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an \n",
    "extrinsic measure?\n",
    "\n",
    "ANS;-In an intrinsic evaluation, quality of NLP systems outputs is evaluated against pre-determined ground truth (reference text) whereas an extrinsic evaluation is aimed at evaluating systems outputs based on their impact on the performance of other NLP systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c694ae75-1425-4e64-9fd9-7dac2d37737e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e27e5f5-7781-4958-a226-f77136dffd33",
   "metadata": {},
   "source": [
    "Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify \n",
    "strengths and weaknesses of a model?\n",
    "\n",
    "ANS:-A confusion matrix represents the prediction summary in matrix form. It shows how many prediction are correct and incorrect per class. It helps in understanding the classes that are being confused by model as other class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1db63-3e69-4b5f-9fe5-abbe3bf11c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c810890-a97c-4ea7-88a4-ba519fefeb6d",
   "metadata": {},
   "source": [
    "Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised \n",
    "learning algorithms, and how can they be interpreted?\n",
    "\n",
    "ANS:-\n",
    "The approach consists of following four steps:\n",
    "\n",
    "(1)Creating a twin-sample of training data.\n",
    "\n",
    "(2)Performing unsupervised learning on twin-sample.\n",
    "\n",
    "(3)Importing results for twin-sample from training set.\n",
    "\n",
    "(4)Calculating similarity between two sets of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3f26f-b55a-49b0-a7fe-b2de8fb47944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe94d989-88ae-4d83-8c3f-0d18d0317c26",
   "metadata": {},
   "source": [
    "Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and \n",
    "how can these limitations be addressed?\n",
    "\n",
    "ANS:-it has some limitations that should be considered, including:\n",
    "\n",
    "* Imbalanced classes\n",
    "* Misclassification costs\n",
    "* Probability predictions\n",
    "* Ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e946c-ad97-426f-84fb-b043f3b3e15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28866ae3-4b42-4702-900d-4efc6b4c8507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
