{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d92f5aa-f6c1-421c-9fdc-249a246272cd",
   "metadata": {},
   "source": [
    "Q1. What is the purpose of grid search cv in machine learning, and how does it work?\n",
    "\n",
    "ANS:-GridSearchCV is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting the best parameter values, predictions are made.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0916c-156a-4376-ac91-b128b2f32dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8afea9f2-7e04-4e42-89d8-3b4f7d4ab720",
   "metadata": {},
   "source": [
    "Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose \n",
    "one over the other?\n",
    "\n",
    "ANS:-The only difference between both the approaches is in grid search we define the combinations and do training of the model whereas in RandomizedSearchCV the model selects the combinations randomly. Both are very effective ways of tuning the parameters that increase the model generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d7f63-4028-439f-a995-faf96c4a87f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc1a086-b18b-488e-ba0b-48c168c1c1a4",
   "metadata": {},
   "source": [
    "Q3. What is data leakage, and why is it a problem in machine learning? Provide an example\n",
    "\n",
    "ANS:-Data leakage is one of the major problems in machine learning which occurs when the data that we are using to train an ML algorithm has the information the model is trying to predict. It is a situation that causes unpredictable and bad prediction outcomes after model deployment.\n",
    "\n",
    "for example data leakage is like when the model takes the random or different values which does not present in real world environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c391f5e0-f670-4940-a5cf-1ba50ce7c66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2834b94a-be0f-432e-8a80-b171a0fae459",
   "metadata": {},
   "source": [
    "Q4. How can you prevent data leakage when building a machine learning model?\n",
    "\n",
    "ANS:-One of the best ways to get rid of data leakage is to perform k-fold cross validation where the overall data is divided into k parts. After dividing into k parts, we use each part as the cross-validation data and the remaining as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf651743-6a86-4dc2-b904-56175d41a91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75f4a0cd-eeee-4677-be3f-cc7383ab3815",
   "metadata": {},
   "source": [
    "Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?\n",
    "\n",
    "ANS:-\n",
    "A confusion matrix is a table that is used to define the performance of a classification algorithm. A confusion matrix visualizes and summarizes the performance of a classification algorithm.It Return matrix which consists of values and provide the idea for positive true negative false positive and false negative value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871b8d3-9707-4689-9d90-add8df0d8931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeabdd8e-e5b8-4212-9065-c08e5f121ce0",
   "metadata": {},
   "source": [
    "Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n",
    "\n",
    "ANS:- the precision and recall  has the different formula which are:-\n",
    "Precision refers to the number of true positives divided by the total number of positive predictions (i.e., the number of true positives plus the number of false positives).\n",
    "\n",
    "Recall, also known as the true positive rate (TPR), is the percentage of data samples that a machine learning model correctly identifies as belonging to a class of interest—the “positive class”—out of the total samples for that class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ccefd6-b28e-44be-b027-8d99c3c8eb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "981e9fd5-4e10-433a-bb6d-3affe49e1127",
   "metadata": {},
   "source": [
    "Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n",
    "\n",
    "ANS:-A confusion matrix is a table that allows you to visualize the performance of a classification model. You can also use the information in it to calculate measures that can help you determine the usefulness of the model. Rows represent predicted classifications, while columns represent the true classes from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c605b6-be21-4cad-be72-ed20baa7156d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee68c45f-5cfc-4d13-986c-33d0ada4c674",
   "metadata": {},
   "source": [
    "Q8. What are some common metrics that can be derived from a confusion matrix, and how are they \n",
    "calculated?\n",
    "\n",
    "ANS:-Confusion matrices can be used to calculate performance metrics for classification models. Of the many performance metrics used, the most common are accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a12a78a-36ae-44fe-988c-a18e8a089e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "875eb514-1554-496d-ac83-14ec8ca94070",
   "metadata": {},
   "source": [
    "Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?\n",
    "\n",
    "ANS:-It gives you the overall accuracy of the model, meaning the fraction of the total samples that were correctly classified by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009cd13-acd6-4614-884f-6e1fe6cd5e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89246ee7-ec81-4cd3-8687-b3dc2bcb5c37",
   "metadata": {},
   "source": [
    "Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning \n",
    "model?\n",
    "\n",
    "ANS:-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
