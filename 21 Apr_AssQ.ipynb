{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01e881e-d125-405e-a0e9-c5b3425d5be3",
   "metadata": {},
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance \n",
    "metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?\n",
    "\n",
    "ANS:-\n",
    "Manhattan Distance is the L1 norm form (L1 norm is the sum of the magnitude of vectors in space), while Euclidean Distance is L2 Norm form (The L2 norm calculates the distance of the vector coordinate from the origin of the vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6d676-2c6b-4e9a-b61d-dfb85a800f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c20304f-c21c-45c7-923c-55ee1ac31c9a",
   "metadata": {},
   "source": [
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be \n",
    "used to determine the optimal k value?\n",
    "\n",
    "ANS:-The optimal K value usually found is the square root of N, where N is the total number of samples. Use an error plot or accuracy plot to find the most favorable K value. KNN performs well with multi-label classes, but you must be aware of the outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e6000e-1daa-427f-812e-567b574b61a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d764cb17-587c-482d-88b0-7c75d42801b6",
   "metadata": {},
   "source": [
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In \n",
    "what situations might you choose one distance metric over the other?\n",
    "\n",
    "ANS:-We mean by the 'best distance metric' (in this review) is the one that allows the KNN to classify test examples with the highest precision, recall and accuracy, i.e. the one that gives best performance of the KNN in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78715dc-9924-47ee-b5c3-b1e58884d92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a06abc1-4d8e-417e-9c3a-01efac245090",
   "metadata": {},
   "source": [
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect \n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve \n",
    "model performance?\n",
    "\n",
    "ANS:-The most important hyperparameter for KNN is the number of neighbors (n_neighbors). Test values between at least 1 and 21, perhaps just the odd numbers. It may also be interesting to test different distance metrics (metric) for choosing the composition of the neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85d9ec2-3b71-4a74-a8db-c8b6a3532c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f226670-e7bf-4136-9b55-366ea37fe057",
   "metadata": {},
   "source": [
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What \n",
    "techniques can be used to optimize the size of the training set?\n",
    "\n",
    "ANS:-\n",
    "The performance of the K-NN algorithm is influenced by three main factors :\n",
    "    \n",
    "The distance function or distance metric used to determine the nearest neighbors.\n",
    "\n",
    "The decision rule used to derive a classification from the K-nearest neighbors.\n",
    "\n",
    "The number of neighbors used to classify the new example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc433f42-9983-4813-abb8-ac8bde086af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "594f81b9-1453-4adb-8c03-f1643d92e9fa",
   "metadata": {},
   "source": [
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you \n",
    "overcome these drawbacks to improve the performance of the model?\n",
    "\n",
    "ANS:-\n",
    "Some Disadvantages of KNN\n",
    "\n",
    "Accuracy depends on the quality of the data.\n",
    "\n",
    "With large data, the prediction stage might be slow.\n",
    "\n",
    "Sensitive to the scale of the data and irrelevant features.\n",
    "\n",
    "Require high memory â€“ need to store all of the training data.\n",
    "\n",
    "Given that it stores all of the training, it can be computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b635dcc-4a06-47ae-9695-8a4270829193",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
